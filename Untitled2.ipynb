{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6c7e6e-9fa0-4652-9574-fda5be59e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gurobipy as gu\n",
    "#from gurobipy import GRB\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import os\n",
    "from intervaltree import Interval, IntervalTree\n",
    "directory = '/home/bionets-og86asub/Documents/greenerai/jobdata_galaxy'\n",
    "configuration_dir = op.join(directory, 'new_configurations')\n",
    "os.makedirs(configuration_dir, exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f67807f3-3a0a-4969-8cab-a988bf60355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntimeperiods = 24*60*60\n",
    "job_delay = 12*60*60\n",
    "# the job data is in seconds.\n",
    "min_timeslots = 1\n",
    "sec_timslots = 1\n",
    "timeslot_factor = min_timeslots*sec_timslots\n",
    "#carbon intensity is reported in 15 minute intervals\n",
    "##CAUTION. Not \n",
    "ci_repeat_factor = 15/(min_timeslots*(sec_timslots/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d91d316-0f31-4509-80be-201ae38a81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, timeslot_factor):\n",
    "    jan2021 = pd.read_csv(path, sep='\\t')\n",
    "    jan2021['run_min'] = jan2021.tool_runtime_in_seconds/60\n",
    "    jan2021['cpu_percent'] = jan2021.tool_cpu_usage_in_nanoseconds/(jan2021.tool_runtime_in_seconds*10**9)\n",
    "    \n",
    "    data =jan2021.sort_values(by = 'job_started_to_run_at')\n",
    "    dd = [int(np.floor(pd.Timedelta(pd.to_datetime(x)- pd.to_datetime(data.job_started_to_run_at[0])).total_seconds()/timeslot_factor)) for x in data.job_started_to_run_at]\n",
    "    data[\"arrival_time\"] = dd\n",
    "    return data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a1b99f1-2c5b-48ed-9ab1-92ad99db8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_system_config(path):\n",
    "    computers = pd.read_csv(path)\n",
    "    ul = np.where(['upload' not in x for x in computers.hostname])[0]\n",
    "    computers = computers.iloc[ul,:]\n",
    "    computers['host_number'] = range(computers.shape[0])\n",
    "    computers[computers['job-02-2020']>2].loc[:, ['hostname','approx_cores', 'approx_memory', 'job-02-2020', 'host_number']]\n",
    "    return computers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "19069ed8-b997-4cef-9578-9892f5ef9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_intensity = pd.read_csv('/home/bionets-og86asub/Documents/greenerai/jobdata_galaxy/galaxy/DE-actual-15.csv')\n",
    "carbon_intensity = carbon_intensity.loc[:, ['startTime', 'ci1', 'ci2', 'ci3', 'ci4', 'ci5']]\n",
    "carbon_intensity['start_timestamp'] = carbon_intensity['startTime'].apply(lambda x: datetime.strptime(str(x), '%Y%m%d%H%M'))\n",
    "carbon_intensity['start_timestamp'] = pd.to_datetime(carbon_intensity['start_timestamp'])\n",
    "carbon_intensity = carbon_intensity.loc[np.repeat(carbon_intensity.index, ci_repeat_factor)].reset_index(drop=True)\n",
    "carbon_intensity = carbon_intensity[carbon_intensity.start_timestamp>=(pd.to_datetime(data.job_started_to_run_at.min())-pd.Timedelta(minutes = 15))]\n",
    "carbon_intensity_per_timeslot = list(carbon_intensity.ci3)\n",
    "carbon_intensity = carbon_intensity[carbon_intensity.start_timestamp<=data.job_ended_at.max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b83fd8f4-b56c-45db-86a8-a266b2145987",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/bionets-og86asub/Documents/greenerai/jobdata_galaxy/galaxy-data-parts/2020-02.csv'\n",
    "data = read_data(path)\n",
    "system_path = '/home/bionets-og86asub/Documents/greenerai/jobdata_galaxy/hostname-config-full.csv'\n",
    "computers = load_system_config(system_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "46859b02-09ba-47fe-8296-6c1432182a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_machine(machines, machines_in_use, machine_map):\n",
    "\n",
    "    approx_cores = int(computers[computers.host_number == machines_in_use]['approx_cores'])\n",
    "    ## Create a hashmap which indicates from which timepoint a core is available again\n",
    "    available_cores = []\n",
    "    for i in range(int(approx_cores)):\n",
    "        available_cores.append(Interval(0, tmax, i))\n",
    "\n",
    "    tree = IntervalTree(available_cores)\n",
    "    \n",
    "    \n",
    "        \n",
    "    machines[machines_in_use]  =  {'approx_memory': computers[computers.host_number == machines_in_use]['approx_memory'],\n",
    "                    'approx_cores':computers[computers.host_number == machines_in_use]['approx_cores'],\n",
    "                   'available_cores':tree}\n",
    "    max_machine = 0\n",
    "    if approx_cores in machine_map:\n",
    "        machine_map[approx_cores].append(machines_in_use)     \n",
    "    else:\n",
    "        machine_map[approx_cores] = [machines_in_use]\n",
    "    if approx_cores> max_machine:\n",
    "            max_machine = approx_cores\n",
    "    machines_in_use +=1\n",
    "\n",
    "    return machines, machines_in_use, machine_map, max_machine\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def check_availability(machine, cores, time, current_time):\n",
    "    tree = machines[machine]['available_cores']\n",
    "    tree.chop(0, current_time)\n",
    "    machines[machine]['available_cores'] = tree\n",
    "    ol = tree.overlap(current_time, current_time+time)\n",
    "    i = 0\n",
    "    l = list(tree)\n",
    "    while len(ol)<cores and i<len(l) and i<48*60*60:\n",
    "        iv = l[i]\n",
    "        ol = tree.overlap(iv.begin, iv.begin+time)\n",
    "        i +=1\n",
    "            \n",
    "    return list(ol)\n",
    "\n",
    "def check_schedule(m, rc, rs, current_time, load):\n",
    "    ol = check_availability(m, rc, rs, current_time)\n",
    "    scheduled = False\n",
    "    if len(ol)> rc:\n",
    "        tree = machines[m]['available_cores']\n",
    "        for j in range(rc):\n",
    "            ind = ol[j].data\n",
    "            tree.removei(ol[j].begin, ol[j].end, ind)\n",
    "            tree.addi(current_time+rs, ol[j].end, ind)\n",
    "        machines[m]['available_cores'] = tree\n",
    "        scheduled = True\n",
    "    return scheduled, [i, current_time, m, rs, rc, load]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613f3f6-71b6-4bac-ba85-3e6cfa8ea862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2456872a-a515-40e4-acb6-5e22ae5bd031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_180655/3920093401.py:3: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  approx_cores = int(computers[computers.host_number == machines_in_use]['approx_cores'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "10000\n",
      "4\n",
      "20000\n",
      "4\n",
      "30000\n",
      "4\n",
      "40000\n",
      "4\n",
      "50000\n",
      "4\n",
      "60000\n",
      "4\n",
      "70000\n",
      "4\n",
      "80000\n",
      "4\n",
      "90000\n",
      "5\n",
      "100000\n",
      "5\n",
      "110000\n",
      "5\n",
      "120000\n",
      "5\n",
      "130000\n",
      "5\n",
      "140000\n",
      "5\n",
      "150000\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "schedule = []\n",
    "machines = {}\n",
    "tmax= data.iloc[-1,]['arrival_time']+int(data.iloc[-1,]['arrival_time'])+1000\n",
    "machines_in_use = 0\n",
    "scheduled_counter = 0\n",
    "failcounter = 0\n",
    "machine_map = {}\n",
    "machines, machines_in_use, machine_map, max_machine = allocate_machine(machines, machines_in_use, machine_map)\n",
    "for i, job in data.iterrows():\n",
    "    scheduled = False\n",
    "    rc = int(job['tool_requested_cores'])\n",
    "    current_time = int(job['arrival_time'])\n",
    "    try:\n",
    "        rs = int(job['tool_runtime_in_seconds'])\n",
    "    except:\n",
    "        continue\n",
    "    best_time = tmax\n",
    "    best_machine = 0\n",
    "\n",
    "    if max_machine < rc:\n",
    "        machines, machines_in_use, machine_map, max_machine = allocate_machine(machines, machines_in_use, machine_map)\n",
    "\n",
    "    k = 0\n",
    "    mkeys = list(machine_map.keys())\n",
    "    while k < len(mkeys) and not scheduled:\n",
    "        mc = mkeys[k]\n",
    "        if mc<rc:\n",
    "            continue\n",
    "        \n",
    "        l = 0\n",
    "        while l < len(machine_map[mc]) and not scheduled:\n",
    "            m = machine_map[mc][l]\n",
    "            scheduled, resc = check_schedule(m, rc, rs, current_time, job['cpu_percent'])\n",
    "            l+=1\n",
    "        k += 1\n",
    "\n",
    "    if not scheduled:\n",
    "        machines, machines_in_use, machine_map, max_machine = allocate_machine(machines, machines_in_use, machine_map)\n",
    "        m = machines_in_use-1\n",
    "        scheduled, resc = check_schedule(m, rc, rs, current_time, job['cpu_percent'])\n",
    "        \n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "        print(machines_in_use)\n",
    "    schedule.append(resc)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "424d994f-00b9-49f1-a34f-69a91746487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_operation(dd, timeslot_factor, start_time):\n",
    "    timedelta = pd.Timedelta(seconds=dd * timeslot_factor)\n",
    "    new_date = start_time + timedelta\n",
    "    return new_date\n",
    "    \n",
    "def split_line(line):\n",
    "    parts = line.replace('[', ',').replace(']', '').split(',')\n",
    "    name = parts[0].strip()\n",
    "    numbers = [int(part.strip()) for part in parts[1:]]\n",
    "    return  numbers\n",
    "def calculateEnergyConsumption1(runtime_seconds, requested_cores, load):\n",
    "    # result in KWh\n",
    "    # Assumptions\n",
    "    PUE = 1.6 # Power Usage Efficiency of the data center\n",
    "    P_m = 0.3725 # Memory power draw,Watts/GB  \n",
    "    P_c =  15.8  # In Watts Assuming Core-i5-10600K  ; value taken from http://calculator.green-algorithms.org/\n",
    "    u_c = 0.50 # core usage factor \n",
    "\n",
    "    t_hour = runtime_seconds / 3600\n",
    "    def ceil_to_power_of_2(num):\n",
    "        return int(2 ** np.ceil(np.log2(num)))\n",
    "    power = t_hour * (load * P_c ) * PUE * 0.001\n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f0ae2cf-92cc-4bc1-939a-0ac008b73bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.to_datetime(data.iloc[0,]['job_started_to_run_at'])\n",
    "jobs = pd.DataFrame(schedule)\n",
    "jobs.columns = ['job', 'time', 'machine', 'runtime_seconds', 'requested_cores', 'cpu_percent']\n",
    "jobs['time_actual'] = jobs['time'].apply(lambda x: reverse_operation(x, timeslot_factor, start_time))\n",
    "jobs['carbon_intensity_new'] = jobs['time'].apply(lambda x: carbon_intensity_per_timeslot[int(x)])\n",
    "ec = []\n",
    "for i, x in jobs.iterrows():\n",
    "    ec.append(calculateEnergyConsumption1(x['runtime_seconds'], x['requested_cores'], x['cpu_percent']))\n",
    "jobs['energy_consumption'] = ec  \n",
    "jobs['co2'] = jobs['energy_consumption']*jobs['carbon_intensity_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e52f13dd-32aa-4e99-882b-97cbac945ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4aeee67-1207-4270-974a-2a99499e1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['co2'].sum()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24747002-3943-4be7-9b36-97c342c0b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2220.9802749996866)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
